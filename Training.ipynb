{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l9aC4KbLRjQg"
      },
      "outputs": [],
      "source": [
        "# COMMON LIBRARIES\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import torch\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# DATA SET PREPARATION AND LOADING\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "# VISUALIZATION\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "# CONFIGURATION\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# EVALUATION\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# TRAINING\n",
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For Dataset in roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from roboflow import Roboflow\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from azure.core.exceptions import ResourceExistsError  # Correct import\n",
        "\n",
        "\n",
        "rf = Roboflow(api_key=\"p7ll5rTRQYfRRG5zTZYK\")\n",
        "project = rf.workspace(\"amodic2c\").project(\"paddy_weed\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco-segmentation\")\n",
        "                \n",
        "dataset_path = dataset.location  # Correct way to get the path\n",
        "\n",
        "# # Azure Blob Storage credentials\n",
        "# \n",
        "# # Initialize Blob Service Client\n",
        "# blob_service_client = BlobServiceClient.from_connection_string(AZURE_CONNECTION_STRING)\n",
        "# container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
        "\n",
        "# # Ensure the container exists\n",
        "# try:\n",
        "#     container_client.create_container()\n",
        "#     print(f\"Created container: {CONTAINER_NAME}\")\n",
        "# except ResourceExistsError:\n",
        "#     print(f\"Container '{CONTAINER_NAME}' already exists.\")\n",
        "\n",
        "# # Upload dataset files to Azure Blob Storage\n",
        "# for root, dirs, files in os.walk(dataset_path):  # Use correct dataset path\n",
        "#     for file_name in files:\n",
        "#         file_path = os.path.join(root, file_name)\n",
        "#         blob_name = os.path.relpath(file_path, dataset_path)  # Preserve folder structure in blob\n",
        "\n",
        "#         # Upload file\n",
        "#         blob_client = container_client.get_blob_client(blob_name)\n",
        "#         with open(file_path, \"rb\") as data:\n",
        "#             blob_client.upload_blob(data, overwrite=True)\n",
        "#         print(f\"Uploaded: {blob_name}\")\n",
        "\n",
        "# print(\"Dataset successfully uploaded to Azure Blob Storage!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category Mapping: {0: 'weed', 1: 'Paddy'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "annotation_file = \"/home/prajjwal/Paddy_weed_detection/paddy_weed-1/test/_annotations_fixed.coco.json\"\n",
        "\n",
        "with open(annotation_file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "category_ids = {c[\"id\"]: c[\"name\"] for c in data[\"categories\"]}\n",
        "print(\"Category Mapping:\", category_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique class IDs in dataset: {0, 1}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "annotation_file = \"/home/prajjwal/Paddy_weed_detection/paddy_weed-1/train/_annotations_fixed.coco.json\"  # Adjust for your dataset format\n",
        "with open(annotation_file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "class_counts = set()\n",
        "for annotation in data[\"annotations\"]:\n",
        "    class_counts.add(annotation[\"category_id\"])\n",
        "\n",
        "print(f\"Unique class IDs in dataset: {class_counts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed COCO annotations saved to /home/prajjwal/Paddy_weed_detection/paddy_weed-1/valid/_annotations_fixed.coco.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Path to your COCO annotation file\n",
        "json_path = \"/home/prajjwal/Paddy_weed_detection/paddy_weed-1/valid/_annotations.coco.json\"\n",
        "\n",
        "# Load the existing COCO JSON\n",
        "with open(json_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Step 1: Fix category mapping\n",
        "# Keep only \"weed\" (ID=0) and \"Paddy\" (ID=1), remove \"Weed\" (ID=2)\n",
        "new_categories = [\n",
        "    {\"id\": 0, \"name\": \"weed\", \"supercategory\": \"none\"},\n",
        "    {\"id\": 1, \"name\": \"Paddy\", \"supercategory\": \"none\"}\n",
        "]\n",
        "\n",
        "# Step 2: Update annotations - Change all instances of \"Weed\" (ID=2) to \"weed\" (ID=0)\n",
        "for ann in data[\"annotations\"]:\n",
        "    if ann[\"category_id\"] == 2:\n",
        "        ann[\"category_id\"] = 0  # Reassign to \"weed\" ID=0\n",
        "\n",
        "# Step 3: Replace the categories section\n",
        "data[\"categories\"] = new_categories\n",
        "\n",
        "# Save the fixed JSON\n",
        "fixed_json_path = \"/home/prajjwal/Paddy_weed_detection/paddy_weed-1/valid/_annotations_fixed.coco.json\"\n",
        "with open(fixed_json_path, \"w\") as f:\n",
        "    json.dump(data, f, indent=4)\n",
        "\n",
        "print(f\"Fixed COCO annotations saved to {fixed_json_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_SET_NAME = dataset_path.split(\"/\")[-1].replace(\" \", \"-\")\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations_fixed.coco.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAIN SET\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset_path, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset_path, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TRAIN_DATA_SET_NAME, \n",
        "    metadata={}, \n",
        "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH, \n",
        "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# TEST SET\n",
        "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
        "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset_path, \"test\")\n",
        "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset_path, \"test\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=TEST_DATA_SET_NAME, \n",
        "    metadata={}, \n",
        "    json_file=TEST_DATA_SET_ANN_FILE_PATH, \n",
        "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# VALID SET\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
        "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset_path, \"valid\")\n",
        "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset_path, \"valid\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "register_coco_instances(\n",
        "    name=VALID_DATA_SET_NAME, \n",
        "    metadata={}, \n",
        "    json_file=VALID_DATA_SET_ANN_FILE_PATH, \n",
        "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['paddy_weed-1-train', 'paddy_weed-1-test', 'paddy_weed-1-valid']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[\n",
        "    data_set\n",
        "    for data_set\n",
        "    in MetadataCatalog.list()\n",
        "    if data_set.startswith(DATA_SET_NAME)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McXFiMu_5Hpa"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jJ2F1BXrrHVn"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import HookBase, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.solver import build_lr_scheduler\n",
        "from detectron2 import model_zoo  # Corrected import\n",
        "import torch\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "class LRSchedulerWithEarlyStopping(HookBase):\n",
        "    def __init__(self, patience=5):\n",
        "        self.patience = patience\n",
        "        self.best_loss = float('inf')\n",
        "        self.waiting = 0\n",
        "        \n",
        "    def after_step(self):\n",
        "        stats = self.trainer.storage.latest()\n",
        "        \n",
        "        # Ensure we're accessing the total_loss or the correct loss value\n",
        "        current_loss = stats['total_loss'] if isinstance(stats['total_loss'], (int, float)) else stats['total_loss'][0]\n",
        "        \n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "            self.waiting = 0\n",
        "        else:\n",
        "            self.waiting += 1\n",
        "            \n",
        "        if self.waiting >= self.patience:\n",
        "            # Ensure the scheduler is initialized\n",
        "            if self.trainer.scheduler is not None:\n",
        "                self.trainer.scheduler.step()\n",
        "            self.waiting = 0\n",
        "\n",
        "class WeedTrainer(DefaultTrainer):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__(cfg)\n",
        "        self.scheduler = build_lr_scheduler(cfg, self.optimizer)  # Initialize the scheduler\n",
        "    \n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.append(LRSchedulerWithEarlyStopping(patience=5))\n",
        "        return hooks\n",
        "\n",
        "def get_optimized_weed_detection_config():\n",
        "    cfg = get_cfg()\n",
        "    ARCHITECTURE = \"mask_rcnn_X_101_32x8d_FPN_3x\"  # Using ResNeXt101\n",
        "    CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
        "    cfg.OUTPUT_DIR = \"/home/prajjwal/Paddy_weed_detection/output\"\n",
        "\n",
        "    # Dataset Configuration\n",
        "    cfg.DATASETS.TRAIN = (\"paddy_weed-1-train\",)\n",
        "    cfg.DATASETS.TEST = (\"paddy_weed-1-test\",)\n",
        "    cfg.DATASETS.VAL = (\"paddy_weed-1-valid\",)\n",
        "\n",
        "    # Model Architecture\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "    cfg.MODEL.MASK_ON = True\n",
        "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Optimized Training Hyperparameters with LR Scheduler support\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "    cfg.SOLVER.BASE_LR = 0.0003\n",
        "    cfg.SOLVER.MAX_ITER = 30000\n",
        "    cfg.SOLVER.STEPS = (20000, 25000, 28000)\n",
        "    cfg.SOLVER.GAMMA = 0.1\n",
        "    cfg.SOLVER.WARMUP_FACTOR = 1.0 / 2000\n",
        "    cfg.SOLVER.WARMUP_ITERS = 2000\n",
        "    cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
        "    cfg.SOLVER.WEIGHT_DECAY = 0.00025\n",
        "    cfg.SOLVER.MOMENTUM = 0.9\n",
        "    cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True\n",
        "    cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0\n",
        "    cfg.SOLVER.CHECKPOINT_PERIOD = 1000 \n",
        "\n",
        "    # ROI Head Configuration\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
        "    cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.25\n",
        "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
        "    cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS = [0.3, 0.5, 0.7]\n",
        "    cfg.MODEL.ROI_HEADS.IOU_LABELS = [0, 1, 1, 1]\n",
        "    assert len(cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS) + 1 == len(cfg.MODEL.ROI_HEADS.IOU_LABELS), \"IoU thresholds and labels are mismatched.\"\n",
        "\n",
        "    # RPN Configuration\n",
        "    cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 256\n",
        "    cfg.MODEL.RPN.POSITIVE_FRACTION = 0.5\n",
        "    cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 6000\n",
        "    cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 1000\n",
        "    cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 3000\n",
        "    cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 500\n",
        "    cfg.MODEL.RPN.NMS_THRESH = 0.7\n",
        "\n",
        "    # Anchor Generator\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256]]\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.25, 0.5, 1.0, 2.0]]\n",
        "\n",
        "    # Input Configuration\n",
        "    cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)\n",
        "    cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
        "    cfg.INPUT.MIN_SIZE_TEST = 800\n",
        "    cfg.INPUT.MAX_SIZE_TEST = 1333\n",
        "    cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
        "    \n",
        "    # Data Augmentation\n",
        "    cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
        "    cfg.INPUT.BRIGHTNESS = 1.0\n",
        "    cfg.INPUT.CONTRAST = 1.0\n",
        "    cfg.INPUT.SATURATION = 1.0\n",
        "    cfg.INPUT.ROTATION = [-15, 15]\n",
        "    \n",
        "    # Dataloader\n",
        "    cfg.DATALOADER.NUM_WORKERS = 4\n",
        "    cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True\n",
        "    cfg.DATALOADER.ASPECT_RATIO_GROUPING = True\n",
        "    \n",
        "    # Evaluation\n",
        "    cfg.TEST.EVAL_PERIOD = 1000\n",
        "    cfg.TEST.DETECTIONS_PER_IMAGE = 100\n",
        "    cfg.TEST.PRECISE_BN.ENABLED = True\n",
        "    cfg.TEST.PRECISE_BN.NUM_ITER = 200\n",
        "    \n",
        "    # Test-Time Augmentation\n",
        "    cfg.TEST.AUG.ENABLED = True\n",
        "    cfg.TEST.AUG.MIN_SIZES = (600, 700, 800, 900, 1000)\n",
        "    cfg.TEST.AUG.MAX_SIZE = 1400\n",
        "    cfg.TEST.AUG.FLIP = True\n",
        "    \n",
        "    # Mixed Precision Training\n",
        "    cfg.SOLVER.AMP.ENABLED = False\n",
        "    \n",
        "    return cfg\n",
        "\n",
        "# Usage example:\n",
        "\n",
        "# cfg = get_optimized_weed_detection_config()\n",
        "# trainer = WeedTrainer(cfg)\n",
        "# trainer.resume_or_load(resume=True)\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced Dataset: 7473 weed, 7473 paddy\n",
            "\u001b[32m[02/10 10:03:37 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[02/10 10:03:37 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 14946 images left.\n",
            "\u001b[32m[02/10 10:03:38 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|\n",
            "|    weed    | 14447        |   paddy    | 20508        |\n",
            "|            |              |            |              |\n",
            "|   total    | 34955        |            |              |\u001b[0m\n",
            "\u001b[32m[02/10 10:03:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[02/10 10:03:38 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[02/10 10:03:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[02/10 10:03:38 d2.data.common]: \u001b[0mSerializing 14946 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[02/10 10:03:38 d2.data.common]: \u001b[0mSerialized dataset takes 38.90 MiB\n",
            "\u001b[32m[02/10 10:03:38 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/10 10:03:38 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "\u001b[32m[02/10 10:03:38 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/prajjwal/Paddy_weed_detection/output/model_0013999.pth ...\n",
            "Training restarted from Step 0 using the provided model checkpoint...\n",
            "\u001b[32m[02/10 10:03:38 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[02/10 10:09:41 d2.utils.events]: \u001b[0m eta: 3 days, 8:20:43  iter: 19  total_loss: 0.9566  loss_cls: 0.07711  loss_box_reg: 0.35  loss_mask: 0.2105  loss_rpn_cls: 0.04868  loss_rpn_loc: 0.2121    time: 17.9278  last_time: 17.6882  data_time: 0.0170  last_data_time: 0.0088   lr: 5.8471e-06  \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "def setup_cfg():\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(\"/home/prajjwal/Paddy_weed_detection/config.yaml\")\n",
        "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    cfg.OUTPUT_DIR = \"/home/prajjwal/Paddy_weed_detection/output2\"\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    cfg.MODEL.WEIGHTS = \"/home/prajjwal/Paddy_weed_detection/output/model_0013999.pth\"\n",
        "    return cfg\n",
        "\n",
        "def balance_dataset():\n",
        "    train_dataset = DatasetCatalog.get(\"paddy_weed-1-train\")\n",
        "    filtered_dataset = [data for data in train_dataset if \"annotations\" in data and data[\"annotations\"]]\n",
        "    weed_samples = [data for data in filtered_dataset if data[\"annotations\"][0][\"category_id\"] == 0]\n",
        "    paddy_samples = [data for data in filtered_dataset if data[\"annotations\"][0][\"category_id\"] == 1]\n",
        "    if not weed_samples or not paddy_samples:\n",
        "        raise ValueError(\"Error: One of the classes (weed or paddy) has no samples after filtering. Check dataset.\")\n",
        "    random.shuffle(weed_samples)\n",
        "    weed_samples = weed_samples[:len(paddy_samples)]\n",
        "    balanced_dataset = weed_samples + paddy_samples\n",
        "    random.shuffle(balanced_dataset)\n",
        "    if \"paddy_weed-1-train-balanced\" in DatasetCatalog.list():\n",
        "        DatasetCatalog.remove(\"paddy_weed-1-train-balanced\")\n",
        "    def get_balanced_dataset():\n",
        "        return balanced_dataset\n",
        "    DatasetCatalog.register(\"paddy_weed-1-train-balanced\", get_balanced_dataset)\n",
        "    MetadataCatalog.get(\"paddy_weed-1-train-balanced\").set(thing_classes=[\"weed\", \"paddy\"])\n",
        "    print(f\"Balanced Dataset: {len(weed_samples)} weed, {len(paddy_samples)} paddy\")\n",
        "    return \"paddy_weed-1-train-balanced\"\n",
        "\n",
        "def restart_training():\n",
        "    cfg = setup_cfg()\n",
        "    balanced_dataset_name = balance_dataset()\n",
        "    cfg.DATASETS.TRAIN = (balanced_dataset_name,)\n",
        "    cfg.DATASETS.TEST = (\"paddy_weed-1-test\",)\n",
        "    cfg.SOLVER.BASE_LR = 0.0003\n",
        "    cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "    cfg.SOLVER.MAX_ITER = 16000\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4\n",
        "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
        "    trainer = DefaultTrainer(cfg)\n",
        "    trainer.resume_or_load(resume=True)\n",
        "    print(\"Training restarted from Step 0 using the provided model checkpoint...\")\n",
        "    trainer.train()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    restart_training()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensorflow training curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VqXTq6SETPTf"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $/content/drive/MyDrive/ColabOutputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGbuq25NXx44"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-bc5ANgXrcs_"
      },
      "outputs": [],
      "source": [
        "f = open('config.yaml', 'w')\n",
        "f.write(cfg.dump())\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
