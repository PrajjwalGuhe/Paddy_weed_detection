{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9aC4KbLRjQg"
      },
      "outputs": [],
      "source": [
        "# COMMON LIBRARIES\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# DATA SET PREPARATION AND LOADING\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "# VISUALIZATION\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# CONFIGURATION\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# EVALUATION\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "# TRAINING\n",
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For local dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "# # Paths for local dataset\n",
        "# LOCAL_DATASET_DIR = \"/path/to/your/local/dataset\"  # Update this with the root directory of your dataset\n",
        "# ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\"\n",
        "\n",
        "# # Paths for training, testing, and validation datasets\n",
        "# TRAIN_DATASET_NAME = \"local-train\"\n",
        "# TRAIN_IMAGES_DIR = os.path.join(LOCAL_DATASET_DIR, \"train\")\n",
        "# TRAIN_ANNOTATIONS_PATH = os.path.join(TRAIN_IMAGES_DIR, ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "# TEST_DATASET_NAME = \"local-test\"\n",
        "# TEST_IMAGES_DIR = os.path.join(LOCAL_DATASET_DIR, \"test\")\n",
        "# TEST_ANNOTATIONS_PATH = os.path.join(TEST_IMAGES_DIR, ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "# VALID_DATASET_NAME = \"local-valid\"\n",
        "# VALID_IMAGES_DIR = os.path.join(LOCAL_DATASET_DIR, \"valid\")\n",
        "# VALID_ANNOTATIONS_PATH = os.path.join(VALID_IMAGES_DIR, ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "# # Function to register a dataset\n",
        "# def register_local_dataset(name, image_dir, annotations_path):\n",
        "#     # Unregister the dataset if it's already registered\n",
        "#     if name in DatasetCatalog.list():\n",
        "#         DatasetCatalog.remove(name)\n",
        "#         MetadataCatalog.remove(name)\n",
        "\n",
        "#     # Register the dataset\n",
        "#     register_coco_instances(\n",
        "#         name=name,\n",
        "#         metadata={},\n",
        "#         json_file=annotations_path,\n",
        "#         image_root=image_dir\n",
        "#     )\n",
        "\n",
        "# # Register local datasets\n",
        "# register_local_dataset(TRAIN_DATASET_NAME, TRAIN_IMAGES_DIR, TRAIN_ANNOTATIONS_PATH)\n",
        "# register_local_dataset(TEST_DATASET_NAME, TEST_IMAGES_DIR, TEST_ANNOTATIONS_PATH)\n",
        "# register_local_dataset(VALID_DATASET_NAME, VALID_IMAGES_DIR, VALID_ANNOTATIONS_PATH)\n",
        "\n",
        "# # Access the metadata and dataset to verify\n",
        "# train_metadata = MetadataCatalog.get(TRAIN_DATASET_NAME)\n",
        "# test_metadata = MetadataCatalog.get(TEST_DATASET_NAME)\n",
        "# valid_metadata = MetadataCatalog.get(VALID_DATASET_NAME)\n",
        "\n",
        "# print(f\"Training dataset registered: {TRAIN_DATASET_NAME}\")\n",
        "# print(f\"Testing dataset registered: {TEST_DATASET_NAME}\")\n",
        "# print(f\"Validation dataset registered: {VALID_DATASET_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For Dataset in roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rIxA5BwnS-S",
        "outputId": "e15731c1-f676-4e99-e49f-6c8caf4b0b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "# Adjust category ids to start from 1\n",
        "def adjust_category_ids(annotations_file_path):\n",
        "    with open(annotations_file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Create a mapping from old category IDs to new category IDs starting from 1\n",
        "    category_mapping = {category['id']: category['id'] + 1 for category in data['categories']}\n",
        "\n",
        "    # Update categories with new ids\n",
        "    for category in data['categories']:\n",
        "        category['id'] = category_mapping[category['id']]\n",
        "\n",
        "    # Update annotations to reflect new category ids\n",
        "    for annotation in data['annotations']:\n",
        "        old_category_id = annotation['category_id']\n",
        "        annotation['category_id'] = category_mapping[old_category_id]\n",
        "\n",
        "    # Save the updated annotations to a new file\n",
        "    updated_annotations_file_path = annotations_file_path.replace(\".json\", \"_adjusted.json\")\n",
        "    with open(updated_annotations_file_path, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "    return updated_annotations_file_path\n",
        "\n",
        "# Roboflow setup\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"djEgfS7pNSTB4vcvlKkw\")\n",
        "project = rf.workspace(\"abhishek-ogefs\").project(\"weed-8dpr6\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"coco-segmentation\")\n",
        "\n",
        "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
        "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\"\n",
        "\n",
        "# Paths for training, testing, and validation sets\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\n",
        "TRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "# Adjust category IDs in the training annotations\n",
        "TRAIN_DATA_SET_ANN_FILE_PATH_ADJUSTED = adjust_category_ids(TRAIN_DATA_SET_ANN_FILE_PATH)\n",
        "\n",
        "# Unregister the dataset from both DatasetCatalog and MetadataCatalog if it's already registered\n",
        "if TRAIN_DATA_SET_NAME in DatasetCatalog.list():\n",
        "    DatasetCatalog.remove(TRAIN_DATA_SET_NAME)\n",
        "    MetadataCatalog.remove(TRAIN_DATA_SET_NAME)\n",
        "\n",
        "# Register the dataset with the adjusted annotations\n",
        "register_coco_instances(\n",
        "    name=TRAIN_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=TRAIN_DATA_SET_ANN_FILE_PATH_ADJUSTED,\n",
        "    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# TEST SET\n",
        "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
        "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n",
        "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "# Adjust category IDs in the test annotations\n",
        "TEST_DATA_SET_ANN_FILE_PATH_ADJUSTED = adjust_category_ids(TEST_DATA_SET_ANN_FILE_PATH)\n",
        "\n",
        "# Unregister the dataset from both DatasetCatalog and MetadataCatalog if it's already registered\n",
        "if TEST_DATA_SET_NAME in DatasetCatalog.list():\n",
        "    DatasetCatalog.remove(TEST_DATA_SET_NAME)\n",
        "    MetadataCatalog.remove(TEST_DATA_SET_NAME)\n",
        "\n",
        "# Register the test dataset with the adjusted annotations\n",
        "register_coco_instances(\n",
        "    name=TEST_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=TEST_DATA_SET_ANN_FILE_PATH_ADJUSTED,\n",
        "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
        ")\n",
        "\n",
        "# VALID SET\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\n",
        "VALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\n",
        "VALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n",
        "\n",
        "# Adjust category IDs in the validation annotations\n",
        "VALID_DATA_SET_ANN_FILE_PATH_ADJUSTED = adjust_category_ids(VALID_DATA_SET_ANN_FILE_PATH)\n",
        "\n",
        "# Unregister the dataset from both DatasetCatalog and MetadataCatalog if it's already registered\n",
        "if VALID_DATA_SET_NAME in DatasetCatalog.list():\n",
        "    DatasetCatalog.remove(VALID_DATA_SET_NAME)\n",
        "    MetadataCatalog.remove(VALID_DATA_SET_NAME)\n",
        "\n",
        "# Register the validation dataset with the adjusted annotations\n",
        "register_coco_instances(\n",
        "    name=VALID_DATA_SET_NAME,\n",
        "    metadata={},\n",
        "    json_file=VALID_DATA_SET_ANN_FILE_PATH_ADJUSTED,\n",
        "    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ1qcYbvRbIo",
        "outputId": "f465c65a-aa99-43c6-c405-3a13bf148913"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Weed-train', 'Weed-test', 'Weed-valid']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[\n",
        "    data_set\n",
        "    for data_set\n",
        "    in MetadataCatalog.list()\n",
        "    if data_set.startswith(DATA_SET_NAME)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McXFiMu_5Hpa"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ2F1BXrrHVn"
      },
      "outputs": [],
      "source": [
        "def get_weed_detection_config():\n",
        "    cfg = get_cfg()\n",
        "\n",
        "    # Base Configuration\n",
        "    ARCHITECTURE = \"mask_rcnn_R_50_FPN_3x\"  # Changed to ResNet-50 for memory efficiency\n",
        "    CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
        "\n",
        "    # Dataset Configuration\n",
        "    cfg.DATASETS.TRAIN = (\"Weed-train\",)\n",
        "    cfg.DATASETS.TEST = (\"Weed-test\",)\n",
        "    cfg.DATASETS.VAL = (\"Weed-valid\",)  # Adding validation dataset explicitly\n",
        "\n",
        "    # Model Architecture\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # Ensure this matches your number of classes\n",
        "    cfg.MODEL.MASK_ON = True  # Enable mask predictions\n",
        "    cfg.MODEL.DEVICE = \"cuda\"  # Use GPU for faster processing\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 4  # Reduced batch size to fit in memory\n",
        "    cfg.SOLVER.BASE_LR = 0.002  # Slightly adjusted for smaller batch size\n",
        "    cfg.SOLVER.MAX_ITER = 15000  # Number of iterations for training\n",
        "    cfg.SOLVER.STEPS = (10000, 13000)  # Steps to reduce learning rate\n",
        "    cfg.SOLVER.GAMMA = 0.1  # LR decay factor\n",
        "    cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000  # Gradual warm-up\n",
        "    cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "    cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
        "    cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
        "    cfg.SOLVER.MOMENTUM = 0.9\n",
        "\n",
        "    # ROI Head Configuration\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # Adjusted for memory usage\n",
        "    cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.5  # Balanced sampling of positive/negative samples\n",
        "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4  # Lower threshold for detection confidence\n",
        "\n",
        "    # RPN Configuration\n",
        "    cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 128  # Reduced for memory efficiency\n",
        "    cfg.MODEL.RPN.POSITIVE_FRACTION = 0.5  # Balanced sampling\n",
        "    cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 10000  # Slightly reduced proposals for training\n",
        "    cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 1500  # Reduced post-NMS proposals for training\n",
        "    cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 5000  # Reduced pre-NMS proposals for testing\n",
        "    cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 800  # Reduced post-NMS proposals for testing\n",
        "    cfg.MODEL.RPN.NMS_THRESH = 0.7  # Standard NMS threshold\n",
        "\n",
        "    # Anchor Generator\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[32, 64, 128, 256, 512]]  # Adjusted anchor sizes\n",
        "    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0, 2.0]]  # Standard aspect ratios\n",
        "\n",
        "    # Loss Weights\n",
        "    cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT = 1.0  # Default loss weights\n",
        "    cfg.MODEL.ROI_MASK_HEAD.LOSS_WEIGHT = 1.0\n",
        "    cfg.MODEL.ROI_HEADS.CLS_LOSS_WEIGHT = 1.0\n",
        "\n",
        "    # Input Configuration\n",
        "    cfg.INPUT.MIN_SIZE_TRAIN = (640, 672, 704, 736, 768, 800)  # Adjusted input size\n",
        "    cfg.INPUT.MAX_SIZE_TRAIN = 1200  # Reduced maximum input size for training\n",
        "    cfg.INPUT.MIN_SIZE_TEST = 800\n",
        "    cfg.INPUT.MAX_SIZE_TEST = 1200  # Adjusted for testing\n",
        "    cfg.INPUT.MASK_FORMAT = \"bitmask\"  # Consistent with Detectron2 requirements\n",
        "\n",
        "    # Data Augmentation\n",
        "    cfg.INPUT.RANDOM_FLIP = \"horizontal\"  # Horizontal flip as augmentation\n",
        "\n",
        "    # Dataloader\n",
        "    cfg.DATALOADER.NUM_WORKERS = 4  # Adjusted for more efficient data loading\n",
        "    cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True  # Ensure only valid annotations are used\n",
        "\n",
        "    # Evaluation\n",
        "    cfg.TEST.EVAL_PERIOD = 500  # Evaluate every 500 iterations\n",
        "    cfg.TEST.DETECTIONS_PER_IMAGE = 100  # Maximum detections per image\n",
        "\n",
        "    # Enable Test-Time Augmentation (TTA)\n",
        "    cfg.TEST.AUG.ENABLED = True\n",
        "    cfg.TEST.AUG.MIN_SIZES = (400, 500, 600, 700, 800)  # Variety of scales\n",
        "    cfg.TEST.AUG.MAX_SIZE = 1200  # Adjusted maximum size for testing\n",
        "    cfg.TEST.AUG.FLIP = True  # Flip testing enabled\n",
        "\n",
        "    # Mixed Precision\n",
        "    cfg.SOLVER.MIXED_PRECISION = True  # Enable mixed precision training for memory optimization\n",
        "\n",
        "    return cfg\n",
        "\n",
        "# Usage\n",
        "cfg = get_weed_detection_config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "hKTypCf6TPWW",
        "outputId": "2cbebf22-afd7-4246-aac8-a72d6b645fe4"
      },
      "outputs": [],
      "source": [
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=True)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensorflow training curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VqXTq6SETPTf"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $/content/drive/MyDrive/ColabOutputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGbuq25NXx44"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bc5ANgXrcs_"
      },
      "outputs": [],
      "source": [
        "f = open('config.yaml', 'w')\n",
        "f.write(cfg.dump())\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
